{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "import datasets\n",
    "import feature_extractors\n",
    "import torch\n",
    "from esvit_swin import extract_features\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from models import ocsvm, isolation_forest, lof\n",
    "from evaluate import avg_auc, avg_cs, custom_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = config.get_cfg_defaults()\n",
    "cfg.merge_from_file('experiments/cifar100_esvit_base.yaml')\n",
    "cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> merge config from esvit/experiments/imagenet/swin/swin_base_patch4_window14_224.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prahtz/GoogleDrive/GitHub/visual_oc_classification/env/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take key teacher in provided checkpoint dict\n",
      "Pretrained weights found at checkpoints/swin_base_w14/checkpoint_best.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head_dense.mlp.0.weight', 'head_dense.mlp.0.bias', 'head_dense.mlp.2.weight', 'head_dense.mlp.2.bias', 'head_dense.mlp.4.weight', 'head_dense.mlp.4.bias', 'head_dense.last_layer.weight_g', 'head_dense.last_layer.weight_v', 'head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n"
     ]
    }
   ],
   "source": [
    "model_name = cfg.FEATURE_EXTRACTOR.NAME.lower()\n",
    "if model_name == 'esvit_swin_base':\n",
    "    model = feature_extractors.EsVitBase(num_blocks=cfg.FEATURE_EXTRACTOR.NUM_BLOCKS)\n",
    "elif model_name == 'esvit_swin_tiny':\n",
    "    model = feature_extractors.EsVitTiny(num_blocks=cfg.FEATURE_EXTRACTOR.NUM_BLOCKS)\n",
    "else:\n",
    "    raise NameError('Feature extractor name invalid.')\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prahtz/GoogleDrive/GitHub/visual_oc_classification/env/lib/python3.8/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset_name = cfg.DATASET.NAME.lower()\n",
    "if dataset_name == 'cifar10':\n",
    "    train_data = datasets.CIFAR10(root='data/', train=True)\n",
    "    test_data = datasets.CIFAR10(root='data/', train=False)\n",
    "elif dataset_name == 'cifar100':\n",
    "    train_data = datasets.CIFAR100(root='data/', train=True)\n",
    "    test_data = datasets.CIFAR100(root='data/', train=False)\n",
    "elif dataset_name == 'fmnist':\n",
    "    train_data = datasets.FMNIST(root='data/', train=True)\n",
    "    test_data = datasets.FMNIST(root='data/', train=False)\n",
    "elif dataset_name == 'catsvsdogs':\n",
    "    train_data = datasets.CatsVsDogs(root='data/cats_vs_dogs', train=True)\n",
    "    test_data = datasets.CatsVsDogs(root='data/cats_vs_dogs', train=False)\n",
    "elif dataset_name == 'bloodcells':\n",
    "    train_data = datasets.BloodCells(root='data/blood_cells', train=True)\n",
    "    test_data = datasets.BloodCells(root='data/blood_cells', train=False)\n",
    "elif dataset_name == 'viewprediction':\n",
    "    train_data = datasets.ViewPrediction(root='data/view_prediction', train=True)\n",
    "    test_data = datasets.ViewPrediction(root='data/view_prediction', train=False)\n",
    "elif dataset_name == 'covid19':\n",
    "    train_data = datasets.COVID19(root='data/covid19', train=True)\n",
    "    test_data = datasets.COVID19(root='data/covid19', train=False)\n",
    "elif dataset_name == 'weatherprediction':\n",
    "    train_data = datasets.WeatherPrediction(root='data/weather', train=True)\n",
    "    test_data = datasets.WeatherPrediction(root='data/weather', train=False)\n",
    "elif dataset_name == 'concretecrack':\n",
    "    train_data = datasets.ConcreteCrack(root='data/crack', train=True)\n",
    "    test_data = datasets.ConcreteCrack(root='data/crack', train=False)\n",
    "elif dataset_name == 'dior':\n",
    "    train_data = datasets.DIOR(root='data/dior', train=True)\n",
    "    test_data = datasets.DIOR(root='data/dior', train=False)\n",
    "else:\n",
    "    raise NameError('Dataset name invalid')\n",
    "\n",
    "batch_size = cfg.EXTRACT.BATCH_SIZE\n",
    "num_workers = cfg.SYSTEM.NUM_WORKERS\n",
    "pin_memory = cfg.SYSTEM.PIN_MEMORY\n",
    "num_classes = len(train_data.class_to_idx.keys())\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=False\n",
    "    )\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "        test_data,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_0': 0, 'class_1': 1, 'class_2': 2, 'class_3': 3, 'class_4': 4, 'class_5': 5, 'class_6': 6, 'class_7': 7, 'class_8': 8, 'class_9': 9, 'class_10': 10, 'class_11': 11, 'class_12': 12, 'class_13': 13, 'class_14': 14, 'class_15': 15, 'class_16': 16, 'class_17': 17, 'class_18': 18, 'class_19': 19}\n"
     ]
    }
   ],
   "source": [
    "print(train_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n",
      "Saving features...\n"
     ]
    }
   ],
   "source": [
    "features_path = cfg.SYSTEM.FEATURES_PATH\n",
    "model_path = model_name + '_last_' + str(cfg.FEATURE_EXTRACTOR.NUM_BLOCKS) + '_blocks'\n",
    "features_path = os.path.join(features_path, model_path)\n",
    "prefix_path = os.path.join(features_path, dataset_name)\n",
    "train_feat_path = prefix_path + '_train.pkl'\n",
    "test_feat_path = prefix_path + '_test.pkl'\n",
    "\n",
    "if os.path.exists(train_feat_path):\n",
    "    print('Loading features...')\n",
    "    features, labels = torch.load(train_feat_path)\n",
    "    features_test, labels_test = torch.load(test_feat_path)\n",
    "else:\n",
    "    print('Extracting features...')\n",
    "    features, labels = extract_features(model, data_loader_train)\n",
    "    features_test, labels_test = extract_features(model, data_loader_test)\n",
    "    os.makedirs(features_path, exist_ok=True)\n",
    "    print('Saving features...')\n",
    "    torch.save([features, labels], train_feat_path)\n",
    "    torch.save([features_test, labels_test], test_feat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_val, labels_train, labels_val = train_test_split(features.numpy(), labels.numpy(), test_size=0.33, random_state=42)\n",
    "classes = list(range(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.TRAIN.METRIC == 'roc_auc':\n",
    "    scoring = 'roc_auc'\n",
    "elif cfg.TRAIN.METRIC == 'custom':\n",
    "    cost_model = cfg.TRAIN.COST_MODEL[0]\n",
    "    scoring = make_scorer(custom_scoring, greater_is_better=False, needs_threshold=True, cost_model=cost_model, sample_weight='balanced')\n",
    "else:\n",
    "    raise NameError('Scoring name invalid.')\n",
    "\n",
    "verbose = cfg.TRAIN.VERBOSE\n",
    "log = ''\n",
    "if cfg.TRAIN.SGDOCSVM:\n",
    "    params = cfg.TRAIN.SGDOCSVM.HYPERPARAMS[0]\n",
    "    best_params = ocsvm.tune_sgd_ocsvm(classes, [features_train, labels_train], [features_val, labels_val], params=params, verbose=verbose, scoring=scoring)\n",
    "    classifiers = ocsvm.train_sgd_ocsvm(classes, [features, labels], best_params)\n",
    "    if scoring == 'roc_auc':\n",
    "        score, scorings = avg_auc(classifiers, [features_test, labels_test])\n",
    "    else:\n",
    "        score, scorings = avg_cs(classifiers, [features_test, labels_test])\n",
    "    log += 'SGD OCSVM\\nHyperparameters:\\n' + str(best_params) + '\\nMetric: ' + cfg.TRAIN.METRIC + '\\nScorings:\\n' + str(scorings) + '\\nAVG: ' + str(score) + '\\n\\n'\n",
    "if cfg.TRAIN.OCSVM:\n",
    "    best_params = ocsvm.tune_ocsvm(classes, [features_train, labels_train], [features_val, labels_val], verbose=0, scoring=scoring)\n",
    "    classifiers = ocsvm.train_ocsvm(classes, [features, labels], best_params)\n",
    "    if scoring == 'roc_auc':\n",
    "        score, scorings = avg_auc(classifiers, [features_test, labels_test])\n",
    "    else:\n",
    "        score, scorings = avg_cs(classifiers, [features_test, labels_test])\n",
    "    log += 'OCSVM\\nHyperparameters:\\n' + str(best_params) + '\\nMetric: ' + cfg.TRAIN.METRIC + '\\nScorings:\\n' + str(scorings) + '\\nAVG: ' + str(score) + '\\n\\n'\n",
    "if cfg.TRAIN.ISOLATION_FOREST:\n",
    "    best_params = isolation_forest.tune_isolation_forest(classes, [features_train, labels_train], [features_val, labels_val], verbose=0, scoring=scoring)\n",
    "    classifiers = isolation_forest.train_isolation_forest(classes, [features, labels], best_params)\n",
    "    if scoring == 'roc_auc':\n",
    "        score, scorings = avg_auc(classifiers, [features_test, labels_test])\n",
    "    else:\n",
    "        score, scorings = avg_cs(classifiers, [features_test, labels_test])\n",
    "    log += 'Isolation Forest\\nHyperparameters:\\n' + str(best_params) + '\\nMetric: ' + cfg.TRAIN.METRIC + '\\nScorings:\\n' + str(scorings) + '\\nAVG: ' + str(score) + '\\n\\n'\n",
    "if cfg.TRAIN.LOF:\n",
    "    best_params = lof.tune_lof(classes, [features_train, labels_train], [features_val, labels_val], verbose=0, scoring=scoring)\n",
    "    classifiers = lof.train_lof(classes, [features, labels], best_params)\n",
    "    if scoring == 'roc_auc':\n",
    "        score, scorings = avg_auc(classifiers, [features_test, labels_test])\n",
    "    else:\n",
    "        score, scorings = avg_cs(classifiers, [features_test, labels_test])\n",
    "    log += 'Local Outliers Factor\\nHyperparameters:\\n' + str(best_params) + '\\nMetric: ' + cfg.TRAIN.METRIC + '\\nScorings:\\n' + str(scorings) + '\\nAVG: ' + str(score) + '\\n\\n'\n",
    "\n",
    "log_path = os.path.join(cfg.SYSTEM.LOG_PATH, model_path)\n",
    "os.makedirs(log_path, exist_ok=True)\n",
    "log_path = os.path.join(log_path, dataset_name)\n",
    "with open(log_path + '.txt', 'w') as f:\n",
    "    f.write(log)\n",
    "    f.flush()\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f3f61b31ad637482490b4579199d2ae160deb70a2fdfd4083f65067dba162ff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
